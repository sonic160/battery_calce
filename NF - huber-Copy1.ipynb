{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from rul_calce_data import individual_battery_run \n",
    "from utility import cal_ttf\n",
    "\n",
    "def rul_battery(t, y, name):\n",
    "    # Calculate true TTF.\n",
    "    threshold = .7*1.1\n",
    "    true_ttf, idx_ttf = cal_ttf(t, y, threshold)\n",
    "    t = t[:idx_ttf+10]\n",
    "    y = y[:idx_ttf+10]\n",
    "    T = len(t) # Number of time steps\n",
    "    \n",
    "    # Define the Parameters.\n",
    "    # For the PF.\n",
    "    sigma_u = np.array([1e-2, 1e-5, 1e-4, 1e-3])\n",
    "    sigma_v = 1e-2\n",
    "    Ns = 1e3\n",
    "    # For the RUL prediction.\n",
    "    max_ite = 60 # Maximun number of prediction states.\n",
    "    max_RUL = 60 # RUL when not failure found.\n",
    "    idx_start = 50\n",
    "    step = 1\n",
    "    idx_pred = np.arange(idx_ttf-idx_start, idx_ttf+step, step, dtype=int) # Index of the prediction instants.\n",
    "    # Create the time.\n",
    "    t_pred = np.arange(t[-1]+1, t[-1] + max_ite + 1, 1) \n",
    "    t_pred = np.concatenate((t, t_pred))\n",
    "    \n",
    "    xh, yh, y_bands, rul_mean, rul_bands, rul, rul_weights, pf = individual_battery_run(t, y, sigma_u, sigma_v, Ns, threshold, idx_ttf, idx_pred, t_pred, max_ite, max_RUL)\n",
    "\n",
    "    # Save the result.\n",
    "    file_name = 'result_' + name + '.pickle'\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump([t, y, threshold, idx_ttf, idx_pred, true_ttf, max_RUL, \n",
    "            xh, yh, y_bands, rul_mean, rul_bands, rul, rul_weights, t_pred,\n",
    "            pf.particles, pf.w\n",
    "        ], f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run particle filtering to estimate the state variables.\n",
    "battery_list = ['CS2_35', 'CS2_36', 'CS2_37', 'CS2_38']\n",
    "# Directly read from the archived data.\n",
    "with open('data_all.pickle', 'rb') as f:\n",
    "    data_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS2_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import drop_outlier_sw\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = data_all['CS2_38']\n",
    "df1 = data_all['CS2_36']\n",
    "df2 = data_all['CS2_37']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', inplace=True)\n",
    "df1.fillna(method='ffill', inplace=True)\n",
    "df2.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['discharging capacity']\n",
    "X1 = df1['discharging capacity']\n",
    "X2 = df2['discharging capacity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = drop_outlier_sw(X,20)\n",
    "idx1 = drop_outlier_sw(X1,20)\n",
    "idx2 = drop_outlier_sw(X2,20)\n",
    "\n",
    "\n",
    "x1 = X.iloc[idx]\n",
    "x2 = X1.iloc[idx1]\n",
    "x3 = X2.iloc[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1.to_csv('X1.csv')\n",
    "X2.to_csv('X2.csv')\n",
    "X3.to_csv('X3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ss = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(x1)\n",
    "X1 = ss.fit_transform(X1)\n",
    "X1 = pd.DataFrame(X1)\n",
    "\n",
    "X2 = pd.DataFrame(x2)\n",
    "X2 = ss.fit_transform(X2)\n",
    "X2 = pd.DataFrame(X2)\n",
    "\n",
    "X3 = pd.DataFrame(x3)\n",
    "X3 = ss.fit_transform(X3)\n",
    "X3 = pd.DataFrame(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1 = X1[:832]\n",
    "X2 = X2[:832]\n",
    "X3 = X3[:832]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "X3 = np.array(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X1.flatten()\n",
    "X2=X2.flatten()\n",
    "X3=X3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(X1[:832])\n",
    "X2 = pd.DataFrame(X2[:864])\n",
    "X3 = pd.DataFrame(X3[:928])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_x1 = np.arange(0,len(X1))\n",
    "index_x2 = np.arange(0,len(X2))\n",
    "index_x3 = np.arange(0,len(X3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_x1 = pd.DataFrame(index_x1)\n",
    "index_x2 = pd.DataFrame(index_x2)\n",
    "index_x3 = pd.DataFrame(index_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_ = pd.concat([index_x1,X1],axis=1,ignore_index=True)\n",
    "X_2_ = pd.concat([index_x2,X2],axis=1,ignore_index=True)\n",
    "X_3_ = pd.concat([index_x3,X3],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_1 = pd.DataFrame(X_1_)\n",
    "x_2 = pd.DataFrame(X_2_)\n",
    "x_3 = pd.DataFrame(X_3_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy = np.arange(0,len(X1))\n",
    "yyy_1 = np.arange(0,len(X2))\n",
    "yyy_2 = np.arange(0,len(X3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def my_func(x, a, b, c, d):\n",
    "    return a*np.exp(b*x)+c*np.exp(d*x)\n",
    "\n",
    "popt, pcov = curve_fit(my_func, yyy,X1[0],p0= np.array([1.1, -5e-5, -1.5e-3, .006]),bounds = ((1, -1e-3, -2e-2, .001), (1.2, -2e-5, -1e-3, .01)))\n",
    "popt1, pcov1 = curve_fit(my_func, yyy_1,X2[0], p0= np.array([1.1, -5e-5, -1.5e-3, .006]),bounds = ((1, -1e-3, -2e-2, .001), (1.2, -2e-5, -1e-3, .01)))\n",
    "popt2, pcov2 = curve_fit(my_func, yyy_2,X3[0], p0= np.array([1.1, -5e-5, -1.5e-3, .006]),bounds = ((1, -1e-3, -2e-2, .001), (1.2, -2e-5, -1e-3, .01)))\n",
    "\n",
    "\n",
    "\n",
    "##x_hat, _ = curve_fit(degradation_mdl,xdata=t_data, ydata=y_data, p0=x0, bounds=bounds)\n",
    "\n",
    "\n",
    "##x0 = np.array([1.1, -5e-5, -1.5e-3, .006])    \n",
    "##bounds = ((1, -1e-3, -2e-2, .001), (1.2, -2e-5, -1e-3, .01))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d= popt\n",
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,b1,c1,d1 = popt1\n",
    "popt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2,b2,c2,d2 = popt2\n",
    "popt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_curve_fit = []\n",
    "\n",
    "for x in yyy:\n",
    "    yyy_curve_fit.append(a*np.exp(b*x)+c*np.exp(d*x))\n",
    "\n",
    "yyy_curve_fit1 = []\n",
    "\n",
    "for x in yyy_1:\n",
    "    yyy_curve_fit1.append(a1*np.exp(b1*x)+c1*np.exp(d1*x))\n",
    "    \n",
    "yyy_curve_fit2 = []\n",
    "\n",
    "for x in yyy_2:\n",
    "    yyy_curve_fit2.append(a2*np.exp(b2*x)+c2*np.exp(d2*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yyy,X1[0])\n",
    "\n",
    "plt.plot(yyy_1,X2[0])\n",
    "\n",
    "plt.plot(yyy_2,yyy_curve_fit2)\n",
    "plt.plot(yyy_2,X3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yyy_1,yyy_curve_fit1)\n",
    "plt.plot(yyy_1,X2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yyy,X1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yyy_2,yyy_curve_fit2)\n",
    "plt.plot(yyy_2,X3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (a+a1+a2)/3\n",
    "bx = (b+b1+b2)/3\n",
    "cx = (c+c1+c2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_curve_fit3 = []\n",
    "for x in yyy_2:\n",
    "    yyy_curve_fit3.append(a*np.exp(b*x)+c*np.exp(d*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yyy,X1[0])\n",
    "\n",
    "plt.plot(yyy_1,X2[0])\n",
    "\n",
    "plt.plot(yyy_2,yyy_curve_fit2)\n",
    "\n",
    "plt.plot(yyy_2,yyy_curve_fit3)\n",
    "\n",
    "plt.plot(yyy_2,X3[0])\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(timeseries_data, n_features):\n",
    "    X, y =[],[]\n",
    "    for i in range(len(timeseries_data)):\n",
    "\t\t# find the end of this pattern\n",
    "        end_ix = i + n_features\n",
    "\t\t# check if we are beyond the sequence\n",
    "        if end_ix > len(timeseries_data)-1:\n",
    "            break\n",
    "\t\t# gather input and output parts of the pattern\n",
    "        seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_input = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = prepare_data(X1[0], n_input)\n",
    "X2, y2 = prepare_data(X2[0], n_input)\n",
    "X3, y3 = prepare_data(X3[0], n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_ = X1.reshape((X1.shape[0], X1.shape[1], 1))\n",
    "X2_ = X2.reshape((X2.shape[0], X2.shape[1], 1))\n",
    "X3_ = X3.reshape((X3.shape[0], X3.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "df_rnn = df_rnn.reshape((len(df_rnn), 1))\n",
    "generated_batches = TimeseriesGenerator(df_rnn, df_rnn, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_rnn = keras.Sequential()\n",
    "model_rnn.add(keras.layers.LSTM(32, activation='selu', input_shape=(n_input, 1),return_sequences=True))\n",
    "model_rnn.add(keras.layers.LSTM(32, activation='selu', input_shape=(n_input, 1),return_sequences=False))\n",
    "model_rnn.add(keras.layers.Dense(64, activation='selu', kernel_regularizer=tf.keras.regularizers.l2(0.0002)))\n",
    "model_rnn.add(keras.layers.Dense(32, activation='selu', kernel_regularizer=tf.keras.regularizers.l2(0.0002)))\n",
    "model_rnn.add(keras.layers.Dense(1))\n",
    "\n",
    "model_rnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =1e-3), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "\n",
    "def expo(y_true,y_pred):\n",
    "    global k \n",
    "    val = y_pred - k - (a * np.exp(b) + c )\n",
    "    k = y_pred\n",
    "    print(val + tf.math.abs(y_true-y_pred))\n",
    "    print(tf.executing_eagerly())\n",
    "    return val + tf.math.abs(y_true-y_pred)\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x):\n",
    "    return (a*(x**2) + b*(x)+ c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tensorflow.abs(error) < 1\n",
    "    squared_loss = tensorflow.square(error) / 2 \n",
    "    linear_loss  = tensorflow.abs(error) - 0.5\n",
    "    print(y_pred.shape)\n",
    "    print(tf.executing_eagerly())\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = (a+a1+a2)/3\n",
    "b = (b+b1+b2)/3\n",
    "c = (c+c1+c2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_1[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 in x_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cycle_arr = []\n",
    "theoretical = []\n",
    "\n",
    "def custom(y_true,y_pred):\n",
    "    global cycle_arr\n",
    "    global x_1\n",
    "    for i in y_true:\n",
    "        if i in x_1.values:\n",
    "            cycle_arr.append(x_1[x_1[1]==i][0].iloc[0])\n",
    "        if i in x_2.values:\n",
    "            cycle_arr.append(x_2[x_2[1]==i][0].iloc[0])\n",
    "        if i in x_3.values:\n",
    "            cycle_arr.append(x_3[x_3[1]==i][0].iloc[0])\n",
    "    \n",
    "    if y_true[0] in x_1.values:\n",
    "        for cycle in cycle_arr:\n",
    "            theoretical.append([a*np.exp(b*(cycle))+c*np.exp(d*(cycle))])\n",
    "        rmse = tensorflow.math.abs(y_true-y_pred)\n",
    "        diff = tensorflow.math.abs((y_pred) - np.array(theoretical))\n",
    "        error = diff + rmse*1.01\n",
    "        print(tensorflow.executing_eagerly())\n",
    "        cycle_arr.clear()\n",
    "        theoretical.clear()\n",
    "        print('x1')\n",
    "        return error\n",
    "\n",
    "    if y_true[0] in x_2.values:\n",
    "        for cycle in cycle_arr:\n",
    "            theoretical.append([a1*np.exp(b1*(cycle))+c1*np.exp(d1*(cycle))])\n",
    "        rmse = tensorflow.math.abs(y_true-y_pred)\n",
    "        diff = tensorflow.math.abs((y_pred) - np.array(theoretical))\n",
    "        error = diff + rmse*1.01\n",
    "        print(tensorflow.executing_eagerly())\n",
    "        cycle_arr.clear()\n",
    "        theoretical.clear()\n",
    "        print('x2')\n",
    "        return error\n",
    "\n",
    "    if y_true[0] in x_3.values:\n",
    "        for cycle in cycle_arr:\n",
    "            theoretical.append([a2*np.exp(b2*(cycle))+c2*np.exp(d2*(cycle))])\n",
    "        rmse = tensorflow.math.abs(y_true-y_pred)\n",
    "        diff = tensorflow.math.abs((y_pred) - np.array(theoretical))\n",
    "        error = diff + rmse*1.01\n",
    "        print(tensorflow.executing_eagerly())\n",
    "        cycle_arr.clear()\n",
    "        theoretical.clear()\n",
    "        print('x3')\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cycle_arr1 = []\n",
    "theoretical1 = []\n",
    "\n",
    "def custom1(y_true,y_pred):\n",
    "    global cycle_arr1\n",
    "    global x_1\n",
    "    for i in y_true:\n",
    "        cycle_arr1.append(x_3[x_3[1]==i][0].iloc[0])\n",
    "    for cycle in cycle_arr1:\n",
    "        theoretical1.append([a1*(cycle)**2+b1*(cycle)+c1])\n",
    "    rmse = tf.math.abs(y_true-y_pred)\n",
    "    diff = tf.math.abs((y_pred) - np.array(theoretical1))\n",
    "    error = diff + rmse\n",
    "    print(tf.executing_eagerly())\n",
    "    cycle_arr1.clear()\n",
    "    theoretical1.clear()\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cycle_arr2 = []\n",
    "theoretical2 = []\n",
    "\n",
    "def custom2(y_true,y_pred):\n",
    "    global cycle_arr2\n",
    "    global x_1\n",
    "    for i in y_true:\n",
    "        cycle_arr2.append(x_1[x_1[1]==i][0].iloc[0])\n",
    "    for cycle in cycle_arr2:\n",
    "        theoretical2.append([a2*(cycle)**2+b2*(cycle)+c2])\n",
    "    rmse = tf.math.abs(y_true-y_pred)\n",
    "    diff = tf.math.abs((y_pred) - np.array(theoretical2))\n",
    "    error = diff + rmse\n",
    "    print(tf.executing_eagerly())\n",
    "    cycle_arr2.clear()\n",
    "    theoretical2.clear()\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Masking, LSTM\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(LSTM(32,\n",
    "                return_sequences=False))\n",
    "\n",
    "model_rnn.add(Dense(16, activation='relu'))\n",
    "\n",
    "model_rnn.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss=custom, metrics=['mse', 'mae', 'mape'],run_eagerly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rnn.fit(X1_,y1, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rnn.fit(X2_,y2, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rnn.fit(X3_,y3, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_rnn = keras.models.load_model('rul_pred_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_all['CS2_35']\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test['discharging capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test)\n",
    "test = ss.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_train_batch = test[550:582]\n",
    "\n",
    "last_train_batch = last_train_batch.reshape((1,n_input,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rnn.predict(last_train_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[583]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_predictions = []\n",
    "\n",
    "first_eval_batch = test[500:500+n_input]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, 1))\n",
    "\n",
    "for i in range(len(test[500:800])):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    current_pred = model_rnn.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    test_predictions.append(current_pred) \n",
    "    \n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "test_predictions.extend(test[:n_input])\n",
    "\n",
    "for i in range(len(test)-n_input+1):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    \n",
    "    dummy = test[i:i+n_input].reshape((1, n_input, 1))\n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = (dummy)\n",
    "    current_pred = model_rnn.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    test_predictions.append(current_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ss.inverse_transform(test)\n",
    "y_pred_future = ss.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(y_pred_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexes_test_rnn = np.arange(500,800)\n",
    "test_predictions = pd.DataFrame(test_predictions, index =indexes_test_rnn)\n",
    "y_pred_future = pd.DataFrame(y_pred_future, index =indexes_test_rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(y_pred_future,linestyle='solid', marker='o', color='b', label='Predicted-inverse scaled')\n",
    "plt.plot(test,linestyle='solid', marker='o', color='g', label='True')\n",
    "\n",
    "\n",
    "plt.axhline(y = .7*1.1, color = 'r', linestyle = '--')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Comparison - RNN\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_pred_future[:-1], test, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Masking, LSTM\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam()\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss',patience =3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,return_sequences=False))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse', metrics = ['mse', 'mae', 'mape', keras.metrics.RootMeanSquaredError(name='rmse')],run_eagerly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X1_,y1, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X2_,y2, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X3_,y3, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_all['CS2_35']\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test['discharging capacity']\n",
    "test = pd.DataFrame(test)\n",
    "test = ss.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_huber = []\n",
    "\n",
    "test_predictions_huber.extend(test[:n_input])\n",
    "\n",
    "for i in range(len(test)-n_input+1):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    \n",
    "    dummy = test[i:i+n_input].reshape((1, n_input, 1))\n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = (dummy)\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    test_predictions_huber.append(current_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ss.inverse_transform(test)\n",
    "y_pred_future_huber = ss.inverse_transform(test_predictions_huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(y_pred_future_huber,linestyle='solid', marker='o', color='b', label='Predicted-inverse scaled')\n",
    "plt.plot(test,linestyle='solid', marker='o', color='g', label='True')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Comparison - RNN\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_pred_future_huber[:-1], test, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_custom = []\n",
    "for k in range(len(test)):\n",
    "    mse_custom.append(mean_squared_error(y_pred_future[k],test[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_huber = []\n",
    "for k in range(len(test)):\n",
    "    mse_huber.append(mean_squared_error(y_pred_future_huber[k],test[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_future_huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(y_pred_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_predictions_huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(mse_custom[100:150],linestyle='solid', marker='o', color='b', label='custom')\n",
    "plt.plot(mse_huber[100:150],linestyle='solid', marker='o', color='g', label='huber')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"mse - error\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import drop_outlier_sw\n",
    "\n",
    "name = battery_list[1]\n",
    "battery = data_all[name]\n",
    "battery.fillna(method='ffill', inplace=True)\n",
    "# Get the time and degradation measurement. Perform filtering.\n",
    "t1 = battery['cycle']\n",
    "y1 = battery['discharging capacity']\n",
    "\n",
    "\n",
    "rolling_window = 20\n",
    "idx = drop_outlier_sw(y1, rolling_window)\n",
    "\n",
    "t1 = np.array(t1[idx])\n",
    "y1 = np.array(y1[idx])\n",
    "\n",
    "\n",
    "\n",
    "name = battery_list[2]\n",
    "battery = data_all[name]\n",
    "battery.fillna(method='ffill', inplace=True)\n",
    "# Get the time and degradation measurement. Perform filtering.\n",
    "t2 = battery['cycle']\n",
    "y2 = battery['discharging capacity']\n",
    "\n",
    "rolling_window = 20\n",
    "idx = drop_outlier_sw(y2, rolling_window)\n",
    "\n",
    "t2 = np.array(t2[idx])\n",
    "y2 = np.array(y2[idx])\n",
    "\n",
    "\n",
    "\n",
    "name = battery_list[3]\n",
    "battery = data_all[name]\n",
    "battery.fillna(method='ffill', inplace=True)\n",
    "# Get the time and degradation measurement. Perform filtering.\n",
    "t3 = battery['cycle']\n",
    "y3 = battery['discharging capacity']\n",
    "\n",
    "rolling_window = 20\n",
    "idx = drop_outlier_sw(y3, rolling_window)\n",
    "\n",
    "t3 = np.array(t3[idx])\n",
    "y3 = np.array(y3[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ttf1, idx_ttf1 = cal_ttf(t1, y1, .7*1.1)\n",
    "true_ttf2, idx_ttf2 = cal_ttf(t2, y2, .7*1.1)\n",
    "true_ttf3, idx_ttf3 = cal_ttf(t3, y3, .7*1.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_rul1 = true_ttf1 - 32\n",
    "initial_rul2 = true_ttf2 - 32\n",
    "initial_rul3 = true_ttf3 - 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate RUL on sliding window\n",
    "\n",
    "window_size = n_input = 32\n",
    "\n",
    "X1 = []\n",
    "Y1 = []\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "\n",
    "window_cycle = initial_rul1\n",
    "while window_cycle > 0:\n",
    "    window_cycle = initial_rul1-k\n",
    "    window = np.array(y1[j:j+window_size])\n",
    "    k+=1\n",
    "    j+=1\n",
    "    X1.append(window)\n",
    "    Y1.append(window_cycle)\n",
    "    \n",
    "X1 = np.array(X1)\n",
    "Y1 = np.array(Y1)\n",
    "\n",
    "\n",
    "##############\n",
    "X2 = []\n",
    "Y2 = []\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "\n",
    "window_cycle = initial_rul2\n",
    "while window_cycle > 0:\n",
    "    window_cycle = initial_rul2-k\n",
    "    window = np.array(y2[j:j+window_size])\n",
    "    k+=1\n",
    "    j+=1\n",
    "    X2.append(window)\n",
    "    Y2.append(window_cycle)\n",
    "    \n",
    "X2 = np.array(X2)\n",
    "Y2 = np.array(Y2)\n",
    "\n",
    "#############\n",
    "\n",
    "X3 = []\n",
    "Y3 = []\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "\n",
    "window_cycle = initial_rul3\n",
    "while window_cycle > 0:\n",
    "    window_cycle = initial_rul3-k\n",
    "    window = np.array(y3[j:j+window_size])\n",
    "    k+=1\n",
    "    j+=1\n",
    "    X3.append(window)\n",
    "    Y3.append(window_cycle)\n",
    "    \n",
    "X3 = np.array(X3)\n",
    "Y3 = np.array(Y3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ss1 = MinMaxScaler()\n",
    "ss2 = MinMaxScaler()\n",
    "ss3 = MinMaxScaler()\n",
    "\n",
    "Y1 = pd.DataFrame(Y1)\n",
    "Y1 = ss1.fit_transform(Y1)\n",
    "\n",
    "Y2 = pd.DataFrame(Y2)\n",
    "Y2 = ss1.fit_transform(Y2)\n",
    "\n",
    "Y3 = pd.DataFrame(Y3)\n",
    "Y3 = ss1.fit_transform(Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1[:608]\n",
    "Y1 = Y1[:608]\n",
    "\n",
    "X1 = X1.reshape((X1.shape[0], X1.shape[1], 1))\n",
    "Y1 = Y1.reshape(Y1.shape[0],1)\n",
    "\n",
    "X2 = X2[:608]\n",
    "Y2 = Y2[:608]\n",
    "X2 = X2.reshape((X2.shape[0], X2.shape[1], 1))\n",
    "Y2 = Y2.reshape(Y2.shape[0],1)\n",
    "\n",
    "X3 = X3[:768]\n",
    "Y3 = Y3[:768]\n",
    "X3 = X3.reshape((X3.shape[0], X3.shape[1], 1))\n",
    "Y3 = Y3.reshape(Y3.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    val = y_pred - m\n",
    "    m = y_pred\n",
    "    print(m)\n",
    "    print(val+ tf.math.abs(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    global m \n",
    "    val = y_pred - m\n",
    "    m = y_pred\n",
    "    print((val))\n",
    "    print(tensorflow.executing_eagerly())\n",
    "    return (val) + tensorflow.math.abs((y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    global m \n",
    "    val = y_pred - m\n",
    "    m = y_true\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tensorflow.abs(error) < 1 + val\n",
    "    squared_loss = tensorflow.square(error) / 2 + tensorflow.square(val)\n",
    "    linear_loss  = tensorflow.abs(error) - 0.5\n",
    "    print(tensorflow.executing_eagerly())\n",
    "    return tensorflow.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(y_true,y_pred):\n",
    "    a = 15\n",
    "    b = 10\n",
    "    err = y_true-y_pred\n",
    "    is_negative_error = err < 0\n",
    "    print(err)\n",
    "    print(tensorflow.executing_eagerly())\n",
    "    under = tensorflow.math.exp((-err/a))-1\n",
    "    over = tensorflow.math.exp((err/b))-1\n",
    "    print(over)\n",
    "    print(tensorflow.executing_eagerly())\n",
    "    return tf.where(is_negative_error, under, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Masking, LSTM, Dropout, BatchNormalization, Bidirectional\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam()\n",
    "callback = tensorflow.keras.callbacks.EarlyStopping(monitor='loss',patience =3)\n",
    "\n",
    "\n",
    "model_rul = Sequential()\n",
    "model_rul.add((LSTM(16,return_sequences = False)))\n",
    "model_rul.add(Dense(8, activation='relu'))\n",
    "model_rul.add(Dense(1, activation='relu'))\n",
    "\n",
    "model_rul.compile(optimizer='adam', loss='mae', metrics=['mse', 'mae', 'mape', tensorflow.keras.metrics.RootMeanSquaredError(name='rmse')],run_eagerly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rul.fit(X1,Y1, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_rul.fit(X2,Y2, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rul.fit(X3,Y3, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future = np.array(y_pred_future)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = np.arange(1,len(y_pred_future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test, idx_test = cal_ttf(cycle, y_pred_future,  .7*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rul_test = true_test - 32\n",
    "rul_test\n",
    "\n",
    "y_test = []\n",
    "k=0\n",
    "\n",
    "window_cycle = rul_test\n",
    "while window_cycle > 0:\n",
    "    window_cycle = rul_test-k\n",
    "    y_test.append(window_cycle)\n",
    "    k+=1\n",
    "    \n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rul_predictions = []\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "\n",
    "first_eval_batch = y_pred_future[:n_input]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, 1))\n",
    "\n",
    "window_cycle = rul_test\n",
    "while window_cycle >= 0:\n",
    "    window_cycle = rul_test-k\n",
    "    window = np.array(y_pred_future[j:j+32])\n",
    "    current_batch = window.reshape((1, n_input, 1))\n",
    "    current_pred = model_rul.predict(current_batch)[0]\n",
    "    rul_predictions.append(current_pred) \n",
    "    j+=1\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_pred = ss1.inverse_transform(rul_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(rul_pred,linestyle='--', marker='o', color='b', label='Predicted RUL')\n",
    "plt.plot(y_test,linestyle='solid', marker='o', color='g', label='True RUL')\n",
    "\n",
    "\n",
    "plt.title(\"Comparison - RNN Outlier removed\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future_huber = np.array(y_pred_future_huber)\n",
    "test = np.array(test)\n",
    "cycle = np.arange(1,len(y_pred_future_huber))\n",
    "true_test, idx_test = cal_ttf(cycle, y_pred_future_huber,  .7*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predictions_custom = []\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "\n",
    "first_eval_batch = y_pred_future_huber[:n_input]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, 1))\n",
    "\n",
    "window_cycle = rul_test\n",
    "while window_cycle >= 0:\n",
    "    window_cycle = rul_test-k\n",
    "    window = np.array(y_pred_future_huber[j:j+32])\n",
    "    current_batch = window.reshape((1, n_input, 1))\n",
    "    current_pred = model_rul.predict(current_batch)[0]\n",
    "    rul_predictions_custom.append(current_pred) \n",
    "    j+=1\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_pred_custom = ss1.inverse_transform(rul_predictions_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predictions_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(rul_pred_custom,linestyle='--', marker='o', color='b', label='Predicted RUL')\n",
    "plt.plot(y_test,linestyle='solid', marker='o', color='g', label='True RUL')\n",
    "\n",
    "\n",
    "plt.title(\"Comparison - RNN Outlier removed\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rul_predictions_test = []\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "\n",
    "first_eval_batch = test[:n_input]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, 1))\n",
    "\n",
    "window_cycle = rul_test\n",
    "while window_cycle >= 0:\n",
    "    window_cycle = rul_test-k\n",
    "    window = np.array(test[j:j+32])\n",
    "    current_batch = window.reshape((1, n_input, 1))\n",
    "    current_pred = model_rul.predict(current_batch)[0]\n",
    "    rul_predictions_test.append(current_pred) \n",
    "    j+=1\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predictions_test = ss1.inverse_transform(rul_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(rul_predictions_test,linestyle='--', marker='o', color='b', label='Predicted RUL')\n",
    "plt.plot(rul_pred_custom,linestyle='--', marker='o', color='r', label='Predicted RUL custom')\n",
    "plt.plot(y_test,linestyle='solid', marker='o', color='g', label='True RUL')\n",
    "plt.plot(rul_pred,linestyle='--', marker='o', color='y', label='Predicted RUL smooth')\n",
    "\n",
    "\n",
    "plt.title(\"Comparison - RNN Outlier removed\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, rul_predictions_test[:-1], squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEURAL FILTERED\n",
    "\n",
    "mean_squared_error(y_test, rul_pred[:-1], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEURAL FILTERED custom loss\n",
    "\n",
    "\n",
    "\n",
    "%load_ext jupyternotify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify\n",
    "\n",
    "mean_squared_error(y_test, rul_pred_custom[:-1], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(rul_pred,linestyle='--', marker='o', color='b', label='Predicted RUL')\n",
    "plt.plot(y_test,linestyle='solid', marker='o', color='g', label='True RUL')\n",
    "\n",
    "plt.xlabel('Cycles elapsed')\n",
    "plt.ylabel('RUL')\n",
    "plt.title(\"RUL Prediction for Traditional Method\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(rul_pred_custom,linestyle='--', marker='o', color='r', label='Multi-Neural Method')\n",
    "plt.plot(y_test,linestyle='solid', marker='o', color='g', label='True RUL')\n",
    "plt.xlabel('Cycles elapsed')\n",
    "plt.ylabel('RUL')\n",
    "plt.title(\"RUL Prediction for Multi-Neural Method\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(rul_predictions_test,linestyle='--', marker='o', color='b', label='Traditional Method')\n",
    "plt.plot(rul_pred_custom,linestyle='--', marker='o', color='r', label='Multi-Neural Method')\n",
    "plt.plot(y_test,linestyle='solid', marker='o', color='g', label='True RUL')\n",
    "plt.title(\"RUL Comparison\", fontsize=18, fontweight=\"bold\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e4347efc9525cc332960ef81a08601dc32726a1c4f3143eac4c61d078948a8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
